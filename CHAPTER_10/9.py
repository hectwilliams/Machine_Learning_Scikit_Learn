'''

  Q.

    Can you list all the hyperparameters you can tweak in a basic MLP?
    
    If the MLP overfits the training data, how could you tweak these hyperparameters to try to solve the problem?

  A. 

    Learning rate:

      Number of neurons in layers 

      Number of hidden layers 

      Kernel initialization scheme 
    
  With unique configuration Randomized Search or Grid Search can be used to find the optimal hyperparameter location in hyperparameter space 

'''