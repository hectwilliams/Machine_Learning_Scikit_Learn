"""
Q. 
    What is an attention mechanism? How does it help?

A. 
    A Technique that allows the decoder to focus on appropiate words (i.e. samples) at each time step. It removes the inherit short-term issue in RNN networks. 
"""